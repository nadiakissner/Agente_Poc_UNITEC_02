# Plan de Implementaci√≥n - Nuevo Flujo RouteA

## üéØ Objetivo
Reemplazar el flujo actual de RouteA por un nuevo flujo conversacional con preguntas una a la vez, l√≥gica condicional, y an√°lisis mejorado del LLM.

## üìã Pre-requisitos
- [ ] Entorno React/TypeScript configurado
- [ ] Backend PHP con WordPress funcionando
- [ ] API Key de OpenAI configurada en `wp-config.php`
- [ ] Base de datos `byw_agente_retencion` accesible
- [ ] Git o control de versiones (para backup)

---

## üîß Fase 1: Preparaci√≥n

### 1.1 Backup del c√≥digo actual
```bash
# En tu directorio del proyecto
cp src/Pages/RouteA.tsx src/Pages/RouteA.BACKUP_2025.tsx
cp agente-retencion-unitec-02.php agente-retencion-unitec-02.BACKUP_2025.php
```

### 1.2 Revisar archivos relacionados
Verificar que estos archivos existen y funcionan:
- [ ] `/SRC/Components/Chat/ChatBubble.tsx` - Componente de mensaje
- [ ] `/SRC/Components/Chat/TypingIndicator.tsx` - Indicador de escritura
- [ ] `/SRC/Components/Ui/input.tsx` - Input de texto
- [ ] `/SRC/Components/Ui/button.tsx` - Bot√≥n
- [ ] `/SRC/Hooks/use-toast.ts` - Toast notifications

---

## üì¶ Fase 2: Implementaci√≥n Frontend

### 2.1 Reemplazar RouteA.tsx

1. **Abrir** `src/Pages/RouteA.tsx`
2. **Seleccionar TODO** (Ctrl+A o Cmd+A)
3. **Eliminar** todo el contenido
4. **Copiar** el contenido completo de `RouteA_NUEVO_FLUJO.tsx`
5. **Pegar** en `RouteA.tsx`
6. **Guardar** archivo

**Verificar:**
```bash
npm run build
# Debe compilar sin errores
```

### 2.2 Probar componente en desarrollo

```bash
npm run dev
# Navegar a RouteA
# Verificar que aparecen los 10 pasos
# Verificar que el chat es fluido
```

**Checklist visual:**
- [ ] Pregunta "¬øQu√© tan motivado...?" aparece
- [ ] Input de texto responde a cambios
- [ ] Typing indicator aparece despu√©s de responder
- [ ] Historial de chat se acumula
- [ ] Bot√≥n Send se habilita/deshabilita correctamente

### 2.3 Probar l√≥gica condicional

**Caso 1: "ambas"**
```
Pregunta 2: "¬øSientes que tus dudas..."
Respuesta: "ambas cosas"
Siguiente: Debe ir a Paso 3 ‚úÖ
```

**Caso 2: "conmigo"**
```
Pregunta 2: "¬øSientes que tus dudas..."
Respuesta: "conmigo, por mi parte"
Siguiente: Debe SALTAR a Paso 5 ‚úÖ
```

### 2.4 Probar validaci√≥n

**Paso 1 - Motivaci√≥n:**
```
Respuesta: "6"
Resultado: Error message ‚ùå (rechaza > 5)

Respuesta: "3"
Resultado: Acepta ‚úÖ
```

---

## ‚öôÔ∏è Fase 3: Implementaci√≥n Backend

### 3.1 Actualizar funci√≥n `agente_procesar_fin_cuestionario()`

**Archivo:** `agente-retencion-unitec-02.php`

**Ubicaci√≥n:** L√≠nea ~770 (buscar "agente_procesar_fin_cuestionario")

**Cambios incluidos en este documento:**
- [ ] ‚úÖ Ya realizado - Extrae respuestas conversacionales
- [ ] ‚úÖ Ya realizado - Construye contexto detallado
- [ ] ‚úÖ Ya realizado - Pasa contexto al LLM

**Verificar en c√≥digo:**
```php
// Debe existir:
$motivacion_inicial = isset( $respuestas_obj['1'] ) ? ... // ‚úÖ
$tipo_duda = isset( $respuestas_obj['2'] ) ? ... // ‚úÖ
$contexto = "El estudiante {$nombre}..." // ‚úÖ

// Debe llamar a LLM:
agente_clasificar_riesgo_con_llm(
    'cuestionario',
    $nombre,
    $carrera,
    $respuestas_obj,
    $contexto  // ‚Üê NUEVO
);
```

### 3.2 Actualizar prompts en `agente_clasificar_riesgo_con_llm()`

**Ubicaci√≥n:** L√≠nea ~1000 (buscar funci√≥n)

**Prompts actualizados:**
- [ ] ‚úÖ Ya realizado - Prompt 'cuestionario' mejorado
- [ ] ‚úÖ Ya realizado - Prompt 'ruta' mejorado

**Verificar en c√≥digo:**
```php
// Debe incluir:
if ( $etapa === 'cuestionario' ) {
    $prompt = <<<PROMPT
Analiza el cuestionario conversacional de un estudiante...
Identifica:
1. Su nivel de motivaci√≥n inicial
2. Si sus dudas son internas o externas
...
PROMPT;
}
```

### 3.3 Probar backend localmente

```bash
# En terminal, verificar sintaxis PHP
php -l agente-retencion-unitec-02.php
# Debe mostrar: No syntax errors detected

# O usar WP-CLI si tienes
wp plugin verify-plugin agente-retencion-unitec-02
```

---

## üß™ Fase 4: Testing Integrado

### 4.1 Test 1: Flujo Completo Normal

**Inicio:** `http://localhost/agente/routeA`

**Pasos a seguir:**
```
1. ¬øQu√© tan motivado? ‚Üí "4"
2. ¬øDudas? ‚Üí "Sobre la carrera, tengo dudas"
3. ¬øClaridad? ‚Üí "3"
4. ¬øDuraci√≥n? ‚Üí "S√≠, me preocupa"
5. ¬øMaterias? ‚Üí "No, creo que puedo"
6. ¬øSalida laboral? ‚Üí "S√≠, tengo dudas"
   [Debe mostrar feedback sobre derivaci√≥n]
7. ¬øAyudar? ‚Üí "S√≠"
8. ¬øDemostrarse? ‚Üí "S√≠"
9. ¬øDinero? ‚Üí "Es importante"
10. ¬øEmpezar? ‚Üí "S√≠"
```

**Verificar:**
- [ ] Cada paso avanza solo despu√©s de responder
- [ ] El feedback aparece en paso 6
- [ ] Se completa sin errores
- [ ] Redirige a `/summary`
- [ ] En BD se guard√≥ con `prioridad_caso = 'pendiente'`

### 4.2 Test 2: Bifurcaci√≥n en Paso 2

**Inicio:** Recargar p√°gina, volver a empezar

**Pasos a seguir:**
```
1. Motivaci√≥n ‚Üí "2"
2. Dudas ‚Üí "Conmigo, no conf√≠o en m√≠"
[Debe SALTAR a paso 5, NO mostrar paso 3-4]
5. ¬øMaterias? ‚Üí "S√≠, me asusta"
6. ¬øSalida? ‚Üí "No s√©"
7-9. [Respuestas]
10. ¬øEmpezar? ‚Üí "No, necesito ayuda"
```

**Verificar:**
- [ ] Paso 3 y 4 se OMITEN
- [ ] Va directamente a paso 5
- [ ] Redirige a `/routeA-riasec` (o muestra mensaje si ruta no existe)

### 4.3 Test 3: Validaci√≥n de Motivaci√≥n

**Paso 1 - Respuesta incorrecta:**
```
Usuario escribe: "mucho"
Click Send
Resultado: Mensaje de error "Por favor, responde un n√∫mero entre 1 y 5"
```

**Verificar:**
- [ ] Rechaza respuesta
- [ ] Input mantiene el valor (no se borra)
- [ ] Usuario puede reintentar

### 4.4 Test 4: Persistencia

**Durante flujo:**
```
1. Responder pregunta 1
2. Recargar p√°gina (F5)
3. Verificar que pregunta 2 aparece
4. Verificar que historial se mantuvo
```

**Verificar:**
- [ ] Historial se recupera desde localStorage
- [ ] Paso actual es correcto
- [ ] Respuestas no se pierden

---

## üîç Fase 5: Validaci√≥n LLM

### 5.1 Verificar respuesta del LLM

**En navegador (F12) ‚Üí Network:**
```
POST /wp-json/gero/v1/procesar-fin-cuestionario
Status: 200 ‚úÖ
Response: {
    "success": true,
    "message": "Cuestionario procesado correctamente",
    "clasificacion_pendiente": true
}
```

### 5.2 Verificar datos en BD

**En phpMyAdmin:**
```sql
SELECT * FROM byw_agente_retencion 
WHERE user_email = 'email@que.testeas'
LIMIT 1;
```

**Verificar campos:**
- [ ] `user_email` ‚úÖ Correcto
- [ ] `user_id` ‚úÖ Correcto
- [ ] `prioridad_caso` = 'pendiente' ‚úÖ
- [ ] `justificacion` = JSON con "cuestionario" ‚úÖ
- [ ] `riesgo_detectado` ‚úÖ Array JSON

**Ejemplo de `justificacion` esperado:**
```json
{
  "cuestionario": "Juan reporta motivaci√≥n media (2/5) con dudas sobre su confianza personal. Tiene preocupaci√≥n sobre capacidad acad√©mica..."
}
```

### 5.3 Verificar logs del LLM

**Archivo:** `/var/log/apache2/error.log` (o logs de WordPress)

**Buscar:**
```
‚úÖ Clasificaci√≥n de cuestionario guardada para: email@...
```

O en caso de error:
```
‚ùå Error en clasificaci√≥n de cuestionario: [error details]
```

---

## üêõ Troubleshooting

### Problema: Pregunta 2 no bifurca correctamente

**Causa:** L√≥gica de detecci√≥n de palabras clave

**Soluci√≥n:**
```typescript
// Revisar en RouteA_NUEVO_FLUJO.tsx la funci√≥n:
const determineNextStep = (response: string): number => {
  const lowerResponse = response.toLowerCase();
  
  // Agregar m√°s palabras clave si es necesario:
  if (lowerResponse.includes("ambas") || 
      lowerResponse.includes("carrera") ||
      lowerResponse.includes("programa")) {
    return 3;  // ‚Üê Paso 3
  }
  // ...
}
```

### Problema: LLM retorna error 401

**Causa:** API Key no configurada o incorrecta

**Soluci√≥n:**
```php
// En wp-config.php:
define('OPENAI_API_KEY', 'sk-...');  // Tu API key real

// Verificar que est√° set:
if (!defined('OPENAI_API_KEY')) {
    die('‚ùå OPENAI_API_KEY not defined');
}
```

### Problema: Frontend no se conecta al endpoint

**Causa:** CORS o ruta incorrecta

**Soluci√≥n:**
1. Verificar que endpoint existe en PHP:
   ```bash
   wp rest-api-client routes
   # Debe listar: /gero/v1/procesar-fin-cuestionario
   ```

2. Verificar en navegador (F12 ‚Üí Network):
   ```
   Request: POST /wp-json/gero/v1/procesar-fin-cuestionario
   Headers: Content-Type: application/json
   ```

### Problema: Respuestas se pierden al recargar

**Causa:** localStorage no se guarda correctamente

**Soluci√≥n:**
```typescript
// En RouteA_NUEVO_FLUJO.tsx:
useEffect(() => {
  localStorage.setItem("routeA_responses", JSON.stringify(responses));
  console.log('‚úÖ Saved to localStorage:', responses);
}, [responses]);

// En console (F12) debe ver el log
```

---

## ‚úÖ Checklist Final

### Antes de Producci√≥n
- [ ] C√≥digo frontend compila sin warnings
- [ ] C√≥digo PHP no tiene errores de sintaxis
- [ ] API Key OpenAI funciona correctamente
- [ ] Todos los 5 tests pasan
- [ ] Base de datos guarda datos correctamente
- [ ] LLM genera justificaciones coherentes
- [ ] localStorage persiste entre recargas
- [ ] Bifurcaci√≥n Paso 2 funciona
- [ ] Feedback Paso 6 aparece
- [ ] Ambas salidas (S√ç/NO) funcionan

### Antes de Lanzamiento a Usuarios
- [ ] Testing con 5+ usuarios reales
- [ ] Validaci√≥n de justificaciones LLM
- [ ] Verificar prioridades asignadas
- [ ] Documentaci√≥n lista
- [ ] Plan de rollback
- [ ] Monitoreo de errores activo

---

## üìû Soporte Durante Implementaci√≥n

Si necesitas ayuda:
1. **Error en Frontend?** ‚Üí Revisar console (F12 ‚Üí Console)
2. **Error en Backend?** ‚Üí Revisar logs de Apache
3. **LLM falla?** ‚Üí Verificar API Key y logs de error
4. **BD vac√≠a?** ‚Üí Revisar tabla existe y permisos

---

**Duraci√≥n estimada de implementaci√≥n:** 2-3 horas
**Duraci√≥n estimada de testing:** 1-2 horas
**Total:** 3-5 horas

---

**Versi√≥n:** 1.0
**Fecha:** Enero 2025
**Estado:** Listo para implementaci√≥n
